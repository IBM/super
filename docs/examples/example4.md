# Super Power 4: Joining Output from Jobs

<img src="images/runvis4.png" align="left" height="125">

You can also pipe the output of a Cloud job to a local pipeline.

<br>
<br>
<br>

## Example

To generate a histogram of the CPU models running in your Cloud, note
how we can do part of the computation in the Cloud, and then use a
local pipeline to assemble the results:

```sh
super run -p3 -- `lscpu | grep "Model name" | cut -f2 -d ":"' | sort | uniq -c
```

# Another Example

<img title="Super takes a normal UNIX command line, and runs it in parallel, in the Cloud" alt="Super auto-scales normal UNIX command lines" src="../blogs/1-Super-Overview/super-lscpu-100-with-progress.gif" align="right" width="680">

Following on from [our previous `cp` example](example2.md#example),
this `super run`, this pipeline uses `wc -l` to generate partial sum
in the Cloud, and then uses a local `awk` to sum the partial sums
generated by the 3 jobs.

```sh
super run -- \
  'cat /s3/ibm/tmp/*.gz | gunzip -c - | grep "WARC-Type: conversion" | wc -l' \
  | awk '{N+=$1} END {print N}'
122272
```

## Other Super Powers

<!--[<img src="images/runvis4.png" height="77">](example4.md)-->
[<img src="images/runvis1.png" height="77">](example1.md)
[<img src="images/runvis2.png" height="77">](example2.md)
[<img src="images/runvis3.png" height="77">](example3.md)
[<img src="images/runvis5.png" height="77">](example5.md)
